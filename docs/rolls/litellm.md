# üç£ LiteLLM Roll

## Overview
Unified LLM API router with OpenAI-compatible interface and providers.

## Why our Chef chose it
- Abstracts provider differences
- Easy fallback/routing
- Fast to integrate

## How it fits Sushi Kitchen
- Typical platter(s): Hosomaki, Gunkanmaki
- Works well with: Ollama, vLLM, cloud LLMs
- Resource notes: CPU-light; network-bound

## Quick start (conceptual)
- Enable the platter that includes this roll.
- Configure env vars and credentials as needed.
- Access the UI/API at the documented port.

## Learn more
- Official site: https://litellm.ai
- Docs: https://docs.litellm.ai
- GitHub: https://github.com/BerriAI/litellm
